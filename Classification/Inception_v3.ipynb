{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tnNiHmwCzrdn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FkX_brPBT2c4"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QOJvq3slDJiS"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 64        \n",
        "# LR = 0.045      \n",
        "LR = 0.001\n",
        "EPOCHS = 30        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVf2wedPDUTi",
        "outputId": "679657a1-dbbe-456e-ef2d-05d55b2b4e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar_train = torchvision.datasets.CIFAR10(root='./train/',\n",
        "                                           train=True,\n",
        "                                           download=True\n",
        "                                          )\n",
        "\n",
        "cifar_test = torchvision.datasets.CIFAR10(root='./test/',\n",
        "                                          train=False,\n",
        "                                          download=True\n",
        "                                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JeM-4ph1GMoI"
      },
      "outputs": [],
      "source": [
        "mean_R, mean_G, mean_B = np.mean(cifar_train.data, axis=(0, 1, 2)) / 255.\n",
        "std_R, std_G, std_B = np.std(cifar_train.data, axis=(0, 1, 2)) / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c7DNAjn6FiTp"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Resize((299, 299)),\n",
        "                                      transforms.Normalize((mean_R, mean_G, mean_B), (std_R, std_G, std_B)),\n",
        "                                      transforms.RandomHorizontalFlip()\n",
        "                                     ])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Resize((299, 299)),\n",
        "                                     transforms.Normalize((mean_R, mean_G, mean_B), (std_R, std_G, std_B)),\n",
        "                                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EfLjQwIDHLvY"
      },
      "outputs": [],
      "source": [
        "cifar_train.transform = train_transform\n",
        "cifar_test.transform = test_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oU7jGZjVV53I"
      },
      "outputs": [],
      "source": [
        "train_sub = torch.utils.data.Subset(cifar_train, range(5000))\n",
        "subLoader = torch.utils.data.DataLoader(train_sub, batch_size=BATCH_SIZE)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(cifar_train,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testLoader = torch.utils.data.DataLoader(cifar_test,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Oi_02J1NoMBC"
      },
      "outputs": [],
      "source": [
        "class conv_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
        "        super(conv_block, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        nn.init.xavier_normal_(self.conv.weight)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        out = self.relu(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KwgcTBaaqXBY"
      },
      "outputs": [],
      "source": [
        "class inception_fig5(nn.Module):\n",
        "    def __init__(self, in_channels, filter_channels):\n",
        "        super(inception_fig5, self).__init__()\n",
        "        channels_1, channels_2, channels_3, channels_4 = filter_channels \n",
        "        self.branch1 = nn.Sequential(conv_block(in_channels, channels_1[0], kernel_size=1, padding='same'),\n",
        "                                   conv_block(channels_1[0], channels_1[1], kernel_size=3, padding='same'),\n",
        "                                   conv_block(channels_1[1], channels_1[2], kernel_size=3, padding='same')\n",
        "                                   )\n",
        "        \n",
        "        self.branch2 = nn.Sequential(conv_block(in_channels, channels_2[0], kernel_size=1, padding='same'),\n",
        "                                   conv_block(channels_2[0], channels_2[1], kernel_size=3, padding='same')\n",
        "                                  )\n",
        "        \n",
        "        self.branch3 = nn.Sequential(nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
        "                                   conv_block(in_channels, channels_3, kernel_size=1, padding='same')\n",
        "                                  )\n",
        "        \n",
        "        self.branch4 = conv_block(in_channels, channels_4, kernel_size=1, padding='same')\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.branch1(x)\n",
        "        out2 = self.branch2(x)\n",
        "        out3 = self.branch3(x)\n",
        "        out4 = self.branch4(x)\n",
        "        out = torch.concat([out1, out2, out3, out4], dim=1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xH9ETY1vAJ7k"
      },
      "outputs": [],
      "source": [
        "class inception_fig6(nn.Module):\n",
        "    def __init__(self, in_channels, filter_channels):\n",
        "        super(inception_fig6, self).__init__()\n",
        "        channels_1, channels_2, channels_3, channels_4 = filter_channels \n",
        "        self.branch1 = nn.Sequential(conv_block(in_channels, channels_1[0], kernel_size=1, padding='same'),\n",
        "                                     conv_block(channels_1[0], channels_1[1], kernel_size=(1, 7), padding='same'),\n",
        "                                     conv_block(channels_1[1], channels_1[2], kernel_size=(7, 1), padding='same'),\n",
        "                                     conv_block(channels_1[2], channels_1[3], kernel_size=(1, 7), padding='same'),\n",
        "                                     conv_block(channels_1[3], channels_1[4], kernel_size=(7, 1), padding='same')\n",
        "                                    )\n",
        "        \n",
        "        self.branch2 = nn.Sequential(conv_block(in_channels, channels_2[0], kernel_size=1, padding='same'),\n",
        "                                   conv_block(channels_2[0], channels_2[1], kernel_size=(1, 7), padding='same'),\n",
        "                                   conv_block(channels_2[1], channels_2[2], kernel_size=(7, 1), padding='same')\n",
        "                                  )\n",
        "        \n",
        "        self.branch3 = nn.Sequential(nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
        "                                   conv_block(in_channels, channels_3, kernel_size=1, padding='same')\n",
        "                                  )\n",
        "        \n",
        "        self.branch4 = conv_block(in_channels, channels_4, kernel_size=1, padding='same')\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.branch1(x)\n",
        "        out2 = self.branch2(x)\n",
        "        out3 = self.branch3(x)\n",
        "        out4 = self.branch4(x)\n",
        "        out = torch.concat([out1, out2, out3, out4], dim=1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RPZ-RLlwBqyq"
      },
      "outputs": [],
      "source": [
        "class inception_fig7(nn.Module):\n",
        "    def __init__(self, in_channels, filter_channels):\n",
        "        super(inception_fig7, self).__init__()\n",
        "        channels_12, channels_34, channels_5, channels_6 = filter_channels\n",
        "\n",
        "        self.branch12 = nn.Sequential(conv_block(in_channels, channels_12[0], kernel_size=1, padding='same'),\n",
        "                                      conv_block(channels_12[0], channels_12[1], kernel_size=3, padding='same')\n",
        "                                     )\n",
        "        self.layer1 = conv_block(channels_12[1], channels_12[2][0], kernel_size=(1, 3), padding='same')\n",
        "        self.layer2 = conv_block(channels_12[1], channels_12[2][1], kernel_size=(3, 1), padding='same')\n",
        "\n",
        "        self.branch34 = conv_block(in_channels, channels_34[0], kernel_size=1, padding='same')\n",
        "        self.layer3 = conv_block(channels_34[0], channels_34[1][0], kernel_size=(1, 3), padding='same')\n",
        "        self.layer4 = conv_block(channels_34[0], channels_34[1][0], kernel_size=(3, 1), padding='same')\n",
        "\n",
        "        self.branch5 = nn.Sequential(nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
        "                                     conv_block(in_channels, channels_5, kernel_size=1, padding='same')\n",
        "                                    )\n",
        " \n",
        "        self.branch6 = conv_block(in_channels, channels_6, kernel_size=1, padding='same')\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out12 = self.branch12(x)\n",
        "        out1 = self.layer1(out12)\n",
        "        out2 = self.layer2(out12)\n",
        "\n",
        "        out34 = self.branch34(x)\n",
        "        out3 = self.layer3(out34)\n",
        "        out4 = self.layer4(out34)\n",
        "\n",
        "        out5 = self.branch5(x)\n",
        "        out6 = self.branch6(x)\n",
        "        out = torch.concat([out1, out2, out3, out4, out5, out6], dim=1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SxwZrCSm8YNw"
      },
      "outputs": [],
      "source": [
        "class inception_dim_red(nn.Module):\n",
        "    def __init__(self, in_channels, filter_channels):\n",
        "        super(inception_dim_red, self).__init__()\n",
        "        channels_1, channels_2 = filter_channels\n",
        "        self.branch1 = nn.Sequential(conv_block(in_channels, channels_1[0], kernel_size=1, padding='same'),\n",
        "                                     conv_block(channels_1[0], channels_1[1], kernel_size=3, padding='same'),\n",
        "                                     conv_block(channels_1[1], channels_1[2], kernel_size=3, stride=2)\n",
        "                                    )\n",
        "\n",
        "        self.branch2 = nn.Sequential(conv_block(in_channels, channels_2[0], kernel_size=1, padding='same'),\n",
        "                                     conv_block(channels_2[0], channels_2[1], kernel_size=3, stride=2)\n",
        "                                    )\n",
        "\n",
        "        self.branch3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.branch1(x)\n",
        "        out2 = self.branch2(x)\n",
        "        out3 = self.branch3(x)\n",
        "        out = torch.concat([out1, out2, out3], dim=1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HNmwZuhqGESo"
      },
      "outputs": [],
      "source": [
        "class Inception_v2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Inception_v2, self).__init__()\n",
        "\n",
        "        self.conv1 = conv_block(3, 32, kernel_size=3, stride=2)\n",
        "        self.conv2 = conv_block(32, 32, kernel_size=3)\n",
        "        self.conv3 = conv_block(32, 64, kernel_size=3, padding='same')\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.conv4 = conv_block(64, 80, kernel_size=3)\n",
        "        self.conv5 = conv_block(80, 192, kernel_size=3, stride=2)\n",
        "        self.conv6 = conv_block(192, 288, kernel_size=3, padding='same')\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.AvgPool2d(kernel_size=(8, 8), stride=1),\n",
        "                                        nn.Flatten(start_dim=1),\n",
        "                                        nn.Dropout(p=0.5),\n",
        "                                        nn.Linear(2048, NUM_CLASSES)\n",
        "                                       )\n",
        "        \n",
        "        self.inception5_1 = inception_fig5(288, [[64, 96, 96], [48, 64], 64, 64])\n",
        "        self.inception5_2 = inception_fig5(288, [[64, 96, 96], [48, 64], 64, 64])\n",
        "        self.inception5_3 = inception_fig5(288, [[64, 96, 96], [48, 64], 64, 64])\n",
        "        self.inecption5_red = inception_dim_red(288, [[64, 96, 96], [256, 384]])\n",
        "\n",
        "        self.inception6_1 = inception_fig6(768, [[128, 128, 128, 128, 192], [128, 128, 192], 192, 192])\n",
        "        self.inception6_2 = inception_fig6(768, [[160, 160, 160, 160, 192], [160, 160, 192], 192, 192])\n",
        "        self.inception6_3 = inception_fig6(768, [[160, 160, 160, 160, 192], [160, 160, 192], 192, 192])\n",
        "        self.inception6_4 = inception_fig6(768, [[192, 192, 192, 192, 192], [192, 192, 192], 192, 192])\n",
        "        self.inception6_5 = inception_fig6(768, [[192, 192, 192, 192, 192], [192, 192, 192], 192, 192])\n",
        "        self.inception6_red = inception_dim_red(768, [[128, 192, 192], [192, 320]])\n",
        "\n",
        "        self.inception7_1 = inception_fig7(1280, [[448, 384, [384, 384]], [384, [384, 384]], 192, 320])\n",
        "        self.inception7_2 = inception_fig7(2048, [[448, 384, [384, 384]], [384, [384, 384]], 192, 320])\n",
        "\n",
        "        self.aux_classifier = nn.Sequential(nn.AvgPool2d(kernel_size=(5, 5), stride=3),\n",
        "                                            nn.Conv2d(768, 128, kernel_size=(1, 1)),\n",
        "                                            nn.Flatten(start_dim=1),\n",
        "                                            nn.Linear(3200, 1024),\n",
        "                                            nn.Dropout(0.4),\n",
        "                                            nn.Linear(1024, NUM_CLASSES)\n",
        "                                           )\n",
        "        for layer in self.aux_classifier:\n",
        "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "                nn.init.xavier_normal_(layer.weight)\n",
        "\n",
        "    def forward(self, x, train):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "\n",
        "        x = self.inception5_1(x)\n",
        "        x = self.inception5_2(x)\n",
        "        x = self.inception5_3(x)\n",
        "        x = self.inecption5_red(x)\n",
        "\n",
        "        x = self.inception6_1(x)\n",
        "        x = self.inception6_2(x)\n",
        "        x = self.inception6_3(x)\n",
        "        x = self.inception6_4(x)\n",
        "        x_a = self.inception6_5(x)\n",
        "        x = self.inception6_red(x_a)\n",
        "\n",
        "        x = self.inception7_1(x)\n",
        "        x = self.inception7_2(x)\n",
        "\n",
        "        model_output = self.classifier(x)\n",
        "        \n",
        "        # Auxiliary Classifier\n",
        "        if train:\n",
        "            aux_output = self.aux_classifier(x_a)\n",
        "            return model_output, aux_output\n",
        "\n",
        "        else:\n",
        "            return model_output\n",
        "\n",
        "model = Inception_v2().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smoothing_param = 0.1\n",
        "def smoothed_categorical_crossentropy(y_true, y_pred):\n",
        "    smooth_positives = 1 - smoothing_param\n",
        "    smooth_negatives = smoothing_param / NUM_CLASSES\n",
        "    y_true = y_true * smooth_positives + smooth_negatives\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    return loss_fn(y_true, y_pred)"
      ],
      "metadata": {
        "id": "pZKKyne1tR19"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KGmcke5CVIA6"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.94)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cTin33cBDQp8"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, Loader):\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    model.train()\n",
        "    for data, target in tqdm(Loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        model_out, aux_out = model(data, train=True)\n",
        "        main_loss = smoothed_categorical_crossentropy(model_out, target)\n",
        "        aux_loss = smoothed_categorical_crossentropy(aux_out, target)\n",
        "        total_loss = main_loss + aux_loss * 0.3\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += total_loss.item() / len(Loader)\n",
        "        train_acc += (torch.argmax(model_out, dim=1) == target).sum() / len(Loader.dataset)\n",
        "\n",
        "    return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "T0ZKQYblDQNB"
      },
      "outputs": [],
      "source": [
        "def test_loop(model, Loader):\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(Loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            model_out = model(data, train=False)\n",
        "            loss = smoothed_categorical_crossentropy(model_out, target)\n",
        "\n",
        "            test_loss += loss.item() / len(Loader)\n",
        "            test_acc += (torch.argmax(model_out, dim=1) == target).sum() / len(Loader.dataset)\n",
        "\n",
        "    return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2v4Ios_HqPJ",
        "outputId": "219ff51a-7fcc-485e-8f18-8aac4a42f6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:34<00:00,  1.19s/it]\n",
            "100%|██████████| 157/157 [01:01<00:00,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH   1 / 30 ]]\n",
            "Train Loss : 3.1704, Train Accuracy : 21.44 %\n",
            "Valid Loss : 2.1232, Valid Accuracy : 27.88 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:38<00:00,  1.25s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH   2 / 30 ]]\n",
            "Train Loss : 2.4729, Train Accuracy : 27.18 %\n",
            "Valid Loss : 1.7672, Valid Accuracy : 31.90 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH   3 / 30 ]]\n",
            "Train Loss : 2.2630, Train Accuracy : 32.48 %\n",
            "Valid Loss : 1.7318, Valid Accuracy : 35.94 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH   4 / 30 ]]\n",
            "Train Loss : 2.1509, Train Accuracy : 35.46 %\n",
            "Valid Loss : 1.6872, Valid Accuracy : 38.52 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH   5 / 30 ]]\n",
            "Train Loss : 2.0457, Train Accuracy : 38.94 %\n",
            "Valid Loss : 1.7284, Valid Accuracy : 39.98 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH   6 / 30 ]]\n",
            "Train Loss : 1.9737, Train Accuracy : 41.36 %\n",
            "Valid Loss : 1.6527, Valid Accuracy : 41.36 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.25s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH   7 / 30 ]]\n",
            "Train Loss : 1.8964, Train Accuracy : 44.90 %\n",
            "Valid Loss : 1.6174, Valid Accuracy : 43.10 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.25s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH   8 / 30 ]]\n",
            "Train Loss : 1.8105, Train Accuracy : 47.56 %\n",
            "Valid Loss : 1.8087, Valid Accuracy : 39.16 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH   9 / 30 ]]\n",
            "Train Loss : 1.7244, Train Accuracy : 50.10 %\n",
            "Valid Loss : 1.3634, Valid Accuracy : 49.69 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  10 / 30 ]]\n",
            "Train Loss : 1.6204, Train Accuracy : 53.32 %\n",
            "Valid Loss : 1.4129, Valid Accuracy : 49.48 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  11 / 30 ]]\n",
            "Train Loss : 1.5371, Train Accuracy : 56.26 %\n",
            "Valid Loss : 1.3711, Valid Accuracy : 52.76 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  12 / 30 ]]\n",
            "Train Loss : 1.4217, Train Accuracy : 60.20 %\n",
            "Valid Loss : 1.4631, Valid Accuracy : 49.94 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  13 / 30 ]]\n",
            "Train Loss : 1.3412, Train Accuracy : 61.90 %\n",
            "Valid Loss : 1.5013, Valid Accuracy : 50.86 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  14 / 30 ]]\n",
            "Train Loss : 1.2723, Train Accuracy : 64.58 %\n",
            "Valid Loss : 1.5426, Valid Accuracy : 50.90 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  15 / 30 ]]\n",
            "Train Loss : 1.1939, Train Accuracy : 66.52 %\n",
            "Valid Loss : 1.5888, Valid Accuracy : 50.32 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  16 / 30 ]]\n",
            "Train Loss : 1.1147, Train Accuracy : 69.16 %\n",
            "Valid Loss : 1.4689, Valid Accuracy : 53.80 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  17 / 30 ]]\n",
            "Train Loss : 1.0643, Train Accuracy : 71.26 %\n",
            "Valid Loss : 1.4281, Valid Accuracy : 55.78 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  18 / 30 ]]\n",
            "Train Loss : 0.9904, Train Accuracy : 73.48 %\n",
            "Valid Loss : 1.3641, Valid Accuracy : 56.53 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  19 / 30 ]]\n",
            "Train Loss : 0.9260, Train Accuracy : 74.82 %\n",
            "Valid Loss : 1.2957, Valid Accuracy : 60.65 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  20 / 30 ]]\n",
            "Train Loss : 0.8297, Train Accuracy : 77.90 %\n",
            "Valid Loss : 1.3740, Valid Accuracy : 58.15 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  21 / 30 ]]\n",
            "Train Loss : 0.7552, Train Accuracy : 79.24 %\n",
            "Valid Loss : 1.3363, Valid Accuracy : 59.94 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  22 / 30 ]]\n",
            "Train Loss : 0.7392, Train Accuracy : 80.30 %\n",
            "Valid Loss : 1.4293, Valid Accuracy : 59.00 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  23 / 30 ]]\n",
            "Train Loss : 0.6920, Train Accuracy : 81.40 %\n",
            "Valid Loss : 1.3734, Valid Accuracy : 61.13 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  24 / 30 ]]\n",
            "Train Loss : 0.6235, Train Accuracy : 83.46 %\n",
            "Valid Loss : 1.5154, Valid Accuracy : 59.42 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  25 / 30 ]]\n",
            "Train Loss : 0.5938, Train Accuracy : 83.72 %\n",
            "Valid Loss : 1.4927, Valid Accuracy : 60.24 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  26 / 30 ]]\n",
            "Train Loss : 0.4811, Train Accuracy : 87.24 %\n",
            "Valid Loss : 1.6425, Valid Accuracy : 60.94 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  27 / 30 ]]\n",
            "Train Loss : 0.4747, Train Accuracy : 87.30 %\n",
            "Valid Loss : 1.5812, Valid Accuracy : 62.17 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  28 / 30 ]]\n",
            "Train Loss : 0.4731, Train Accuracy : 87.26 %\n",
            "Valid Loss : 1.7290, Valid Accuracy : 59.80 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:03<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  29 / 30 ]]\n",
            "Train Loss : 0.4110, Train Accuracy : 89.02 %\n",
            "Valid Loss : 1.9210, Valid Accuracy : 57.90 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:39<00:00,  1.26s/it]\n",
            "100%|██████████| 157/157 [01:02<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[ EPOCH  30 / 30 ]]\n",
            "Train Loss : 0.3484, Train Accuracy : 90.86 %\n",
            "Valid Loss : 1.8468, Valid Accuracy : 59.48 %\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_loss, train_acc = train_loop(model, subLoader)\n",
        "    val_loss, val_acc = test_loop(model, testLoader)\n",
        "    # lr_scheduler.step()\n",
        "\n",
        "    print(f'\\n[[ EPOCH  {epoch:2d} / {EPOCHS} ]]')\n",
        "    print(f'Train Loss : {train_loss:.4f}, Train Accuracy : {train_acc*100:.2f} %')\n",
        "    print(f'Valid Loss : {val_loss:.4f}, Valid Accuracy : {val_acc*100:.2f} %\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Inception-v3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}